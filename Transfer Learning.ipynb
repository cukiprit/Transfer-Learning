{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3S-E6D8YGaR"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDpklNxKYLKX"
      },
      "source": [
        "Transfer learning dibuat untuk memecahkan masalah computer vision, model yang telah dilatih pada dataset berukuran besar yang berisi gambar umum mampu dipakai sebagai model dasar yang membantu mengenali fitu/bentuk benda pada dunia nyata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73aTSI1QYBU8",
        "outputId": "1b5815bd-c528-4f5a-a3e7-7d1123827745"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "  -O /tmp/Chessman-image-dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-16 15:13:30--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M  1.61MB/s    in 41s     \n",
            "\n",
            "2021-06-16 15:14:11 (1.42 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXDJUxcvYn3B"
      },
      "source": [
        "import os\n",
        "import zipfile as zf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zf.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    zoom_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdB07LPDZdvY",
        "outputId": "9fdeb2ef-0161-491b-b37d-57466fb88133"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 8,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 16,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 499 images belonging to 6 classes.\n",
            "Found 52 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCJUW4EEaAY-"
      },
      "source": [
        "Disini kita mulai mengimplementasikan transfer learning. Untuk model yang kita pilih sebagai model dasar transfer learning adalah ResNet152V2. Model ini memiliki 152 layer dan tersedia di library keras.\n",
        "\n",
        "Untuk mengimplementasikan transfer learning kita perlu menambahkan 2 baris kode berbeda. Layer pertama pada model kita adalah model yang kita pakai untuk transfer learning. Kita cukup memanggil kelas ResNet152V2 dan mengisi parameter:\n",
        "\n",
        "\n",
        "\n",
        "> weight : parameter weight kita mengisi nilai 'imagenet' yang berarti kita akan menggunakan model ResNet152V2\n",
        "\n",
        "\n",
        "> include_top : parameter ini bernilai boolean. Maksudnya adalah jika ingin tetap memakai layer terakhir dari model resnet\n",
        "\n",
        "\n",
        "> input_tensor : sesuai dengan namanya parameter ini menspesifikasikan ukuran dari input\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIqZm4w5Z-en",
        "outputId": "80c7fc8c-7cca-4100-861d-11fcf3f0237c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    ResNet152V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(150, 150, 3))),\n",
        "                                    tf.keras.layers.Dropout(0.4),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(256, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWm3CmrRcfsl"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDnHQWWNczze",
        "outputId": "6142b069-e555-4166-d7df-72df5498bef2"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    epochs = 50,\n",
        "    verbose = 2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 123s - loss: 6.4987 - accuracy: 0.4469 - val_loss: 1.2659 - val_accuracy: 0.6923\n",
            "Epoch 2/50\n",
            "63/63 - 112s - loss: 1.5559 - accuracy: 0.6794 - val_loss: 1.2446 - val_accuracy: 0.6923\n",
            "Epoch 3/50\n",
            "63/63 - 112s - loss: 1.3735 - accuracy: 0.6934 - val_loss: 1.1046 - val_accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "63/63 - 112s - loss: 0.7160 - accuracy: 0.7956 - val_loss: 0.7700 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "63/63 - 112s - loss: 0.5432 - accuracy: 0.8377 - val_loss: 0.8445 - val_accuracy: 0.7308\n",
            "Epoch 6/50\n",
            "63/63 - 112s - loss: 0.5456 - accuracy: 0.8437 - val_loss: 0.7880 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "63/63 - 112s - loss: 0.4080 - accuracy: 0.8617 - val_loss: 0.8260 - val_accuracy: 0.7885\n",
            "Epoch 8/50\n",
            "63/63 - 112s - loss: 0.5764 - accuracy: 0.8497 - val_loss: 0.7371 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "63/63 - 112s - loss: 0.5623 - accuracy: 0.8637 - val_loss: 0.6751 - val_accuracy: 0.8462\n",
            "Epoch 10/50\n",
            "63/63 - 112s - loss: 0.5967 - accuracy: 0.8577 - val_loss: 1.0616 - val_accuracy: 0.7692\n",
            "Epoch 11/50\n",
            "63/63 - 112s - loss: 0.3773 - accuracy: 0.8737 - val_loss: 1.0905 - val_accuracy: 0.8077\n",
            "Epoch 12/50\n",
            "63/63 - 112s - loss: 0.2781 - accuracy: 0.9178 - val_loss: 0.7061 - val_accuracy: 0.8269\n",
            "Epoch 13/50\n",
            "63/63 - 112s - loss: 0.2974 - accuracy: 0.9078 - val_loss: 0.7455 - val_accuracy: 0.8077\n",
            "Epoch 14/50\n",
            "63/63 - 112s - loss: 0.2736 - accuracy: 0.9158 - val_loss: 0.8745 - val_accuracy: 0.8077\n",
            "Epoch 15/50\n",
            "63/63 - 112s - loss: 0.2918 - accuracy: 0.9158 - val_loss: 0.9399 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "63/63 - 112s - loss: 0.2341 - accuracy: 0.9279 - val_loss: 1.1550 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "63/63 - 112s - loss: 0.2895 - accuracy: 0.9218 - val_loss: 0.6642 - val_accuracy: 0.7885\n",
            "Epoch 18/50\n",
            "63/63 - 112s - loss: 0.3447 - accuracy: 0.9138 - val_loss: 1.2576 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "63/63 - 112s - loss: 0.5880 - accuracy: 0.8778 - val_loss: 1.5834 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "63/63 - 112s - loss: 0.7260 - accuracy: 0.8577 - val_loss: 1.6916 - val_accuracy: 0.6923\n",
            "Epoch 21/50\n",
            "63/63 - 113s - loss: 0.2802 - accuracy: 0.9339 - val_loss: 1.2292 - val_accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "63/63 - 112s - loss: 0.2452 - accuracy: 0.9299 - val_loss: 0.5677 - val_accuracy: 0.8462\n",
            "Epoch 23/50\n",
            "63/63 - 112s - loss: 0.2614 - accuracy: 0.9178 - val_loss: 1.1006 - val_accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "63/63 - 112s - loss: 0.1886 - accuracy: 0.9499 - val_loss: 0.8436 - val_accuracy: 0.7885\n",
            "Epoch 25/50\n",
            "63/63 - 112s - loss: 0.1492 - accuracy: 0.9459 - val_loss: 0.5767 - val_accuracy: 0.8462\n",
            "Epoch 26/50\n",
            "63/63 - 113s - loss: 0.1175 - accuracy: 0.9659 - val_loss: 0.4565 - val_accuracy: 0.8654\n",
            "Epoch 27/50\n",
            "63/63 - 112s - loss: 0.0969 - accuracy: 0.9699 - val_loss: 0.3880 - val_accuracy: 0.8654\n",
            "Epoch 28/50\n",
            "63/63 - 112s - loss: 0.1257 - accuracy: 0.9659 - val_loss: 0.7220 - val_accuracy: 0.8269\n",
            "Epoch 29/50\n",
            "63/63 - 112s - loss: 0.1803 - accuracy: 0.9519 - val_loss: 0.9228 - val_accuracy: 0.7692\n",
            "Epoch 30/50\n",
            "63/63 - 112s - loss: 0.2432 - accuracy: 0.9319 - val_loss: 0.4334 - val_accuracy: 0.8654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fc608f3c9e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}